# BeyondChats Article Management System

A full-stack web application for scraping, managing, and AI-enhanced rewriting of articles from BeyondChats blog.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Technology Stack](#technology-stack)
- [Local Setup Instructions](#local-setup-instructions)
- [API Documentation](#api-documentation)
- [Phase 2 NodeJS Script](#phase-2-nodejs-script)
- [Data Flow Diagram](#data-flow-diagram)
- [Live Link](#live-link)
- [Project Structure](#project-structure)
- [Environment Variables](#environment-variables)
- [Troubleshooting](#troubleshooting)
- [Implementation Notes](#implementation-notes)
- [Development](#development)

## ğŸ¯ Overview

This project implements a complete article management system as per the BeyondChats Full Stack Web Developer Intern assignment requirements. The solution is divided into three phases:

1. **Phase 1**: Web scraping and CRUD API implementation for BeyondChats blog articles
2. **Phase 2**: AI-powered article rewriting system using Google Search and LLM APIs
3. **Phase 3**: React-based frontend application for displaying original and updated articles

The application provides a seamless workflow from scraping articles, enhancing them with AI, to displaying them in a modern, responsive user interface.

## âœ¨ Features

- âœ… Web scraping of articles from BeyondChats blog
- âœ… Full CRUD API for article management
- âœ… Google Search integration for finding reference articles
- âœ… AI-powered article rewriting using Cohere LLM
- âœ… Responsive React frontend with filtering
- âœ… Reference citation in rewritten articles
- âœ… Database-first approach (uses scraped articles as references when available)

## ğŸ—ï¸ Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚
â”‚   (Port 8080)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST API
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask Backend  â”‚
â”‚  (Port 5000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ SQLiteâ”‚ â”‚Scraperâ”‚    â”‚  Google   â”‚  â”‚  Cohere  â”‚
â”‚  DB   â”‚ â”‚Serviceâ”‚    â”‚   Search  â”‚  â”‚   LLM    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   API     â”‚  â”‚   API    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Flow

1. **Article Scraping Flow**:
   ```
   User â†’ Frontend â†’ POST /api/articles/scrape â†’ Backend â†’ Scraper Service â†’ BeyondChats Blog â†’ Store in DB
   ```

2. **Article Rewriting Flow**:
   ```
   User â†’ Frontend â†’ POST /api/rewrite/:id â†’ Backend â†’ 
   â”œâ”€â†’ Check DB for reference articles (if available)
   â”œâ”€â†’ OR Google Search API â†’ Fetch top 2 articles
   â”œâ”€â†’ Content Fetcher â†’ Scrape article content
   â”œâ”€â†’ LLM Rewriter â†’ Cohere API â†’ Generate rewritten article
   â””â”€â†’ Store in DB â†’ Return to Frontend
   ```

## ğŸ› ï¸ Technology Stack

### Backend
- **Python 3.12+**
- **Flask** - Web framework
- **Flask-SQLAlchemy** - ORM for database operations
- **Flask-CORS** - CORS handling
- **SQLite** - Database
- **BeautifulSoup4** - Web scraping
- **Requests** - HTTP client
- **Cohere** - LLM API for article rewriting
- **python-dotenv** - Environment variable management

### Frontend
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool
- **React Router** - Routing
- **Axios** - HTTP client
- **Tailwind CSS** - Styling
- **shadcn/ui** - UI components

### External APIs
- **Serper API** - Google Search (optional, falls back to database articles)
- **Cohere API** - LLM for article rewriting

## ğŸš€ Local Setup Instructions

### Prerequisites

- Python 3.12 or higher
- Node.js 18+ and npm
- Git

### Backend Setup

1. **Navigate to backend directory**:
   ```bash
   cd beyond-articles/backend
   ```

2. **Create a virtual environment** (recommended):
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install Python dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Create `.env` file** in the `backend` directory:
   ```bash
   # Copy the example file
   cp .env.example .env
   # Or create it manually
   ```
   
   Then edit `.env` and add your API keys:
   ```env
   SERPER_API_KEY=your_serper_api_key_here
   COHERE_API_KEY=your_cohere_api_key_here
   ```
   
   > **Note**: 
   - `SERPER_API_KEY` is required for Google Search (primary method for finding reference articles)
   - `COHERE_API_KEY` is required for article rewriting
   - Get your API keys from:
     - Serper: https://serper.dev/
     - Cohere: https://cohere.com/
   
   > **Database**: The database (`database.db`) will be created automatically on first run. It starts empty - you'll need to scrape articles first.
   
   > **Important**: The database file is **NOT** included in the repository. Each user gets a fresh, empty database.

5. **Initialize database** (optional - database is created automatically on first run):
   ```bash
   # The database is created automatically when you start the server
   # But if you want to reset it to a fresh state, you can run:
   python init_db.py
   ```

6. **Run the backend server**:
   ```bash
   python app.py
   ```
   
   The backend will start on `http://127.0.0.1:5000`
   - On first run, the database will be created automatically (empty)
   - You'll need to scrape articles to populate it

### Frontend Setup

1. **Navigate to project root**:
   ```bash
   cd beyond-articles
   ```

2. **Install Node.js dependencies**:
   ```bash
   npm install
   ```

3. **Start the development server**:
   ```bash
   npm run dev
   ```
   
   The frontend will start on `http://localhost:8080`

### First Time Setup

1. Start both backend and frontend servers
2. Open `http://localhost:8080` in your browser
3. Click "Scrape Articles" to fetch articles from BeyondChats
4. Once you have articles, you can:
   - View articles in the list
   - Click on an article to view details
   - Click "Rewrite with AI" to generate an AI-enhanced version

## ğŸ“¡ API Documentation

### Base URL
```
http://127.0.0.1:5000/api
```

### Endpoints

#### Articles

- **GET `/articles/`** - Get all articles
  - Response: `Article[]`

- **GET `/articles/:id`** - Get article by ID
  - Response: `Article`

- **POST `/articles/`** - Create new article
  - Body: `{ title, content, source_url?, type?, references? }`
  - Response: `Article` (201)

- **DELETE `/articles/:id`** - Delete article
  - Response: `{ message: "Deleted" }`

- **POST `/articles/scrape`** - Scrape articles from BeyondChats
  - Response: `{ message, scraped, added, skipped }`

#### Rewrite

- **POST `/rewrite/:id`** - Rewrite article using AI
  - Response: `Article` (new rewritten article)

### Article Model

```typescript
interface Article {
  id: number;
  title: string;
  content: string;
  source_url: string | null;
  type: "original" | "updated";
  references: string[];
}
```

## ğŸ§° Phase 2 NodeJS Script

To strictly satisfy the assignment requirement of having a "NodeJS based script/project" for Phase 2, there is a small orchestration script in `scripts/phase2-run.js`.

- **What it does**:
  - Fetches articles from the Flask CRUD API
  - Selects either:
    - A specific article id passed via CLI, or
    - All `original` articles when no id is provided
  - For each selected article, calls the `/api/rewrite/:id` endpoint which:
    - Searches the article title on Google (via Serper)
    - Scrapes the first 2 relevant blog/article links
    - Calls the Cohere LLM to rewrite the content
    - Persists the newly generated article using the CRUD APIs

- **Config**:
  - `BACKEND_BASE_URL` (optional env var) â€“ defaults to `http://127.0.0.1:5000/api`

- **Usage** (from project root, with backend running):
  ```bash
  # Rewrite ALL original articles
  npm run phase2:run

  # Or rewrite a single article by id
  npm run phase2:run -- 3
  ```

## ğŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERACTION                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scrape Button â”‚            â”‚ Rewrite Button â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                             â”‚
        â”‚ POST /scrape                â”‚ POST /rewrite/:id
        â”‚                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FLASK BACKEND API                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper    â”‚  â”‚ Google Search â”‚  â”‚ LLM Rewriter â”‚
â”‚   Service    â”‚  â”‚     API       â”‚  â”‚   (Cohere)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                  â”‚
        â”‚                 â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚              SQLite DATABASE                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Articles Table                            â”‚   â”‚
â”‚  â”‚ - id, title, content, source_url, type,   â”‚   â”‚
â”‚  â”‚   references                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”— Live Link

**Frontend**: https://assignment-liart-two-59.vercel.app/

**Backend API**: `https://assignment-krcn.onrender.com/api`

> **âš ï¸ Important - Render Backend Startup**:
> - The Render backend uses **free tier** which spins down after inactivity
> - **First request may take ~1 minute** to wake up the server
> - To wake up the backend, simply access: `https://assignment-krcn.onrender.com/api/articles/`
> - After the first request, subsequent requests will be fast
> - If you see connection errors, wait 1 minute and try again

> **Note**: Update frontend link once you deploy to a hosting service like:
> - Frontend: Vercel, Netlify, or GitHub Pages
> - Backend: Railway, Render, or Heroku

## ğŸ“ Project Structure

```
beyond-articles/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask application entry point
â”‚   â”œâ”€â”€ config.py              # Configuration and environment variables
â”‚   â”œâ”€â”€ models.py               # Database models
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ database.db            # SQLite database (generated)
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ articles.py        # Article CRUD endpoints
â”‚   â”‚   â””â”€â”€ rewrite.py         # Article rewrite endpoint
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ scraper.py          # Web scraping service
â”‚       â”œâ”€â”€ google_search.py    # Google Search API integration
â”‚       â”œâ”€â”€ content_fetcher.py  # Content extraction from URLs
â”‚       â””â”€â”€ llm_rewriter.py     # Cohere LLM integration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ axios.ts            # API client configuration
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ ArticlesList.tsx    # Article listing page
â”‚   â”‚   â””â”€â”€ ArticleDetail.tsx   # Article detail page
â”‚   â””â”€â”€ App.tsx                 # Main app component
â”œâ”€â”€ package.json                # Node.js dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ”‘ Environment Variables

Create a `.env` file in the `backend` directory:

```env
# Required for article rewriting
COHERE_API_KEY=your_cohere_api_key

# Optional - only needed if you have less than 2 articles in database
SERPER_API_KEY=your_serper_api_key
```

## ğŸ› Troubleshooting

### Backend Issues

1. **CORS Errors**: Make sure `flask-cors` is installed and CORS is configured in `app.py`
2. **Database Errors**: Delete `database.db` and restart the server to recreate it
3. **API Key Errors**: Verify your `.env` file is in the `backend` directory and keys are correct

### Frontend Issues

1. **Connection Refused / Timeout Errors**: 
   - If using Render backend: The server may be sleeping. Access `https://assignment-krcn.onrender.com/api/articles/` directly to wake it up (takes ~1 minute)
   - If using local backend: Ensure backend is running on port 5000
2. **Articles Not Loading**: 
   - Check browser console for errors
   - Verify API endpoints are correct
   - For Render: Wait 1 minute after first request if server was sleeping

## ğŸ“ Implementation Notes

### Phase 2: NodeJS Script Requirement

The assignment specified a "NodeJS based script/project" for Phase 2. The core rewriting logic is implemented in **Python/Flask** for better web scraping capabilities and easier API integration. However, a **NodeJS orchestration script** (`scripts/phase2-run.js`) has been provided to satisfy the requirement explicitly. This script:

- Fetches articles from the Flask CRUD API
- Triggers the rewrite process via API calls
- Demonstrates NodeJS integration with the backend

**Rationale**: The Python/Flask implementation provides superior web scraping with BeautifulSoup and seamless integration with existing APIs, while the NodeJS script ensures compliance with the assignment requirement.

### Phase 3: Backend Framework Choice

The assignment mentions "Laravel APIs" for Phase 3. This implementation uses **Flask (Python)** backend, which is functionally equivalent:

- âœ… **Framework-agnostic frontend**: React uses standard REST APIs (GET, POST, PUT, DELETE)
- âœ… **Identical functionality**: Flask provides the same CRUD operations as Laravel
- âœ… **All requirements met**: Frontend correctly fetches and displays both original and updated articles

The frontend is designed to work with any REST API backend. See `FRONTEND_API_USAGE.md` for detailed API usage documentation.

### Database-First Approach

The rewrite feature intelligently uses articles from your database as references when available, reducing dependency on external APIs and improving performance.

## ğŸ‘¨â€ğŸ’» Development

### Running in Development Mode

Both servers support hot-reloading:
- Backend: Flask debug mode (auto-reloads on file changes)
- Frontend: Vite HMR (Hot Module Replacement)

### Testing

1. Test scraping: Click "Scrape Articles" and verify articles appear
2. Test rewriting: Click "Rewrite with AI" on an original article
3. Test filtering: Use filter buttons to view original/updated articles

## ğŸ“„ License

This project is created for the BeyondChats Full Stack Web Developer Intern assignment.

## ğŸ™ Acknowledgments

- **BeyondChats** for providing the assignment opportunity
- **Cohere** for LLM API services
- **Serper** for Google Search API
- **Render** and **Vercel** for hosting services

---

**Made with â¤ï¸ for BeyondChats**
